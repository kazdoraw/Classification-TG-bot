# –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç: Medical Image Analysis Telegram Bot

**–ü—Ä–æ–µ–∫—Ç:** Telegram-–±–æ—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π  
**–ê–≤—Ç–æ—Ä:** Kazdoraw  
**–î–∞—Ç–∞:** 2 –¥–µ–∫–∞–±—Ä—è 2024  
**Repository:** https://github.com/kazdoraw/Classification-TG-bot

---

## üìã –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ](#–≤–≤–µ–¥–µ–Ω–∏–µ)
2. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞](#–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-–ø—Ä–æ–µ–∫—Ç–∞)
3. [–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π](#–æ–±—É—á–µ–Ω–∏–µ-–º–æ–¥–µ–ª–µ–π)
4. [–†–µ–∑—É–ª—å—Ç–∞—Ç—ã](#—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
5. [Telegram Bot](#telegram-bot)
6. [–í—ã–≤–æ–¥—ã](#–≤—ã–≤–æ–¥—ã)
7. [–ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è](#–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)

---

## 1. –í–≤–µ–¥–µ–Ω–∏–µ

### 1.1 –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å Telegram-–±–æ—Ç–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ë–æ—Ç –¥–æ–ª–∂–µ–Ω:
- –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (retina/blood/scene)
- –ü—Ä–∏–º–µ–Ω—è—Ç—å —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —É–¥–æ–±–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ

### 1.2 –ó–∞–¥–∞—á–∏

1. **Primary Classification:** –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
2. **Retina Segmentation:** –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫—Ä–æ–≤–µ–Ω–æ—Å–Ω—ã—Ö —Å–æ—Å—É–¥–æ–≤ –Ω–∞ —Å–Ω–∏–º–∫–∞—Ö —Å–µ—Ç—á–∞—Ç–∫–∏ (U-Net)
3. **Blood Cell Detection:** –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏ —Å –ø–æ–¥—Å—á—ë—Ç–æ–º (YOLOv8)
4. **Scene Classification:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—â–∏—Ö —Å—Ü–µ–Ω (CIFAR-10)
5. **Telegram Bot:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å

### 1.3 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

**Framework & Libraries:**
- PyTorch 2.1.2 / torchvision
- Ultralytics YOLOv8
- aiogram 3.3.0 (Telegram bot)
- Python 3.12

**–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:**
- Git/GitHub –¥–ª—è –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
- Conda –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏–µ–º
- Shell scripts –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏

---

## 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

### 2.1 –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```
Classification-TG-bot/
‚îú‚îÄ‚îÄ bot/                    # Telegram bot
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ handlers.py        # Message handlers
‚îÇ   ‚îú‚îÄ‚îÄ models_loader.py   # Models manager
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Helper functions
‚îú‚îÄ‚îÄ src/                    # Training & inference
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unet.py        # U-Net architecture
‚îÇ   ‚îú‚îÄ‚îÄ train_*.py         # Training scripts
‚îÇ   ‚îú‚îÄ‚îÄ inference_*.py     # Inference modules
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Global config
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Utilities
‚îú‚îÄ‚îÄ models/                 # Trained models & artifacts
‚îú‚îÄ‚îÄ data/                   # Datasets (excluded from git)
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îî‚îÄ‚îÄ *.sh                   # Shell scripts
```

### 2.2 Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏

```
User ‚Üí Photo ‚Üí Telegram Bot
  ‚Üì
Primary Classifier (ResNet-18)
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   retina    ‚îÇ    blood     ‚îÇ    scene     ‚îÇ
‚Üì             ‚Üì              ‚Üì
U-Net         YOLOv8         ResNet-18
Segmentation  Detection      CIFAR-10
  ‚Üì             ‚Üì              ‚Üì
Overlay       Bounding boxes  Top-3 classes
+ Stats       + Cell counts   + Confidence
  ‚Üì             ‚Üì              ‚Üì
User ‚Üê Result ‚Üê Telegram Bot
```

### 2.3 Datasets

| Dataset | Source | Samples | Purpose |
|---------|--------|---------|---------|
| **Custom Primary** | Kaggle | 440 | Primary classification (retina/blood/scene) |
| **DRIVE** | Medical DB | 20 train + 20 test | Retina vessel segmentation |
| **BCCD** | Roboflow | 364 (291/73 split) | Blood cell detection |
| **CIFAR-10** | torchvision | 60,000 (50K/10K) | Scene classification |

---

## 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### 3.1 Primary Classifier

**–¶–µ–ª—å:** –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (retina/blood/scene) –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ):**

#### 3.1.1 ResNet-18 (–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
- **Transfer learning** –æ—Ç ImageNet
- **Epochs:** 10
- **Val Accuracy:** 100.00% ‚úì
- **–í—Ä–µ–º—è:** ~5 –º–∏–Ω—É—Ç

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```python
model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)
model.fc = nn.Linear(512, 3)  # 3 classes
optimizer = Adam(lr=0.001)
loss = CrossEntropyLoss()
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- Perfect separation –Ω–∞ validation
- –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è (3-4 epochs)
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è production

#### 3.1.2 Baseline CNN
- **Custom architecture:** 3 conv blocks
- **Val Accuracy:** 98.86%
- –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è baseline

#### 3.1.3 Vision Transformer (ViT)
- **Pretrained:** ViT-B/16
- **Val Accuracy:** 98.86%
- –ú–µ–¥–ª–µ–Ω–Ω–µ–µ —á–µ–º ResNet-18

**–í—ã–≤–æ–¥:** ResNet-18 –≤—ã–±—Ä–∞–Ω –¥–ª—è production (100% accuracy + —Å–∫–æ—Ä–æ—Å—Ç—å)

---

### 3.2 U-Net Retina Segmentation

**–¶–µ–ª—å:** –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫—Ä–æ–≤–µ–Ω–æ—Å–Ω—ã—Ö —Å–æ—Å—É–¥–æ–≤ –Ω–∞ —Å–Ω–∏–º–∫–∞—Ö –≥–ª–∞–∑–Ω–æ–≥–æ –¥–Ω–∞

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
- **Model:** U-Net (encoder-decoder —Å skip connections)
- **Input:** 256x256 RGB
- **Output:** 256x256 binary mask

**Dataset:**
- **DRIVE:** 20 train / 4 validation
- **Augmentation:** Rotation, flip, brightness, contrast

**Training:**
```python
Loss = 0.7 * DiceLoss + 0.3 * BCELoss(pos_weight=10.0)
Optimizer = Adam(lr=0.0001)
Epochs = 20 (early stopping patience=7)
Batch size = 4
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| Metric | Train | Validation |
|--------|-------|------------|
| **Dice** | 0.5932 | **0.5103** |
| **IoU** | 0.4507 | 0.3899 |
| **BCE Loss** | 0.1234 | 0.1567 |

**–ê–Ω–∞–ª–∏–∑:**
- Validation Dice 0.51 - –ø—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è –º–∞–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (20 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
- –ù–µ–±–æ–ª—å—à–æ–π overfitting (train 0.59 vs val 0.51)
- –£–ª—É—á—à–µ–Ω–∏–µ –≤ 2.8x –æ—Ç baseline (Dice ~0.18)

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**
- `pos_weight=10.0` –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤ (vessels << background)
- Synchronized transforms –¥–ª—è image+mask
- Early stopping –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è overfitting

---

### 3.3 YOLOv8 Blood Cell Detection

**–¶–µ–ª—å:** –î–µ—Ç–µ–∫—Ü–∏—è –∏ –ø–æ–¥—Å—á—ë—Ç –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏ (WBC, RBC, Platelets)

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
- **Model:** YOLOv8n (nano - —Å–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è)
- **Input:** 416x416 (optimized –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
- **Classes:** 3 (WBC, RBC, Platelets)

**Dataset:**
- **BCCD:** 364 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Üí YOLO format
- **Split:** 291 train / 73 validation
- **Conversion:** VOC XML ‚Üí YOLO txt

**Training:**
```python
Epochs = 20 (early stopping patience=5)
Image size = 416x416
Batch size = 16
Optimizer = SGD(lr=0.01, momentum=0.937)
Augmentation = minimal (–¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| Metric | Score |
|--------|-------|
| **mAP50** | **0.935** (93.5%) |
| **mAP50-95** | 0.636 |
| **Precision** | 0.869 |
| **Recall** | 0.904 |

**Per-Class Performance:**

| Class | mAP50 | Precision | Recall |
|-------|-------|-----------|--------|
| **WBC** | 0.989 | 0.961 | 0.954 |
| **RBC** | 0.910 | 0.843 | 0.905 |
| **Platelets** | 0.906 | 0.803 | 0.853 |

**–ê–Ω–∞–ª–∏–∑:**
- –û—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è nano –º–æ–¥–µ–ª–∏
- WBC –¥–µ—Ç–µ–∫—Ç–∏—Ä—É—é—Ç—Å—è –ª—É—á—à–µ –≤—Å–µ–≥–æ (–∫—Ä—É–ø–Ω—ã–µ, –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ)
- RBC –∏ Platelets —Å–ª–æ–∂–Ω–µ–µ –∏–∑-–∑–∞ —Ä–∞–∑–º–µ—Ä–∞
- –í—Ä–µ–º—è inference: ~0.5-1 —Å–µ–∫—É–Ω–¥–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ

---

### 3.4 ResNet-18 CIFAR-10 Classification

**–¶–µ–ª—å:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—â–∏—Ö —Å—Ü–µ–Ω –Ω–∞ 10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
- **Model:** ResNet-18 transfer learning
- **Input:** 32x32 RGB ‚Üí resized
- **Output:** 10 classes (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck)

**Dataset:**
- **CIFAR-10:** 50,000 train / 10,000 test
- **Preprocessing:** Normalize to ImageNet stats

**Training:**
```python
Epochs = 15
Batch size = 64
Optimizer = Adam(lr=0.001)
Scheduler = ReduceLROnPlateau(factor=0.5, patience=3)
Loss = CrossEntropyLoss()
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**

| Metric | Train | Validation |
|--------|-------|------------|
| **Accuracy** | 84.34% | **82.87%** |
| **F1 Score** | 0.8463 | **0.8282** |
| **Loss** | 0.452 | 0.497 |

**Per-Class F1 Scores:**

| Class | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| airplane | 0.81 | 0.88 | 0.85 |
| automobile | 0.87 | 0.92 | 0.90 |
| bird | 0.80 | 0.79 | 0.79 |
| **cat** | 0.70 | 0.60 | **0.65** ‚ö†Ô∏è |
| deer | 0.84 | 0.83 | 0.84 |
| **dog** | 0.69 | 0.81 | **0.75** ‚ö†Ô∏è |
| frog | 0.88 | 0.86 | 0.87 |
| horse | 0.88 | 0.87 | 0.88 |
| ship | 0.90 | 0.89 | 0.90 |
| **truck** | **0.92** | 0.82 | 0.87 |

**–ê–Ω–∞–ª–∏–∑:**
- –ë–ª–∏–∑–∫–æ –∫ —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–µ 85% (–¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ 82.87%)
- –õ—É—á—à–∏–µ: truck (0.92), ship (0.90), automobile (0.87)
- –°–ª–æ–∂–Ω—ã–µ: cat (0.65), dog (0.75) - –≤–∏–∑—É–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –º–ª–µ–∫–æ–ø–∏—Ç–∞—é—â–∏—Ö
- –ù–µ–±–æ–ª—å—à–æ–π gap train/val (1.5%) - —Ö–æ—Ä–æ—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è

**Best Epoch:** 13/15

---

## 4. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### 4.1 –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–æ–¥–µ–ª–µ–π

| Model | Architecture | Dataset Size | Accuracy/mAP | Training Time | Status |
|-------|-------------|--------------|--------------|---------------|--------|
| **Primary** | ResNet-18 | 440 | **100.0%** | 5 min | ‚úÖ Production |
| **U-Net** | U-Net | 20 | Dice **0.51** | 10 min | ‚úÖ Production |
| **YOLO** | YOLOv8n | 364 | mAP50 **0.935** | 10 min | ‚úÖ Production |
| **CIFAR-10** | ResNet-18 | 60K | **82.87%** | 90 min | ‚úÖ Production |

### 4.2 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä Primary Classifier

| Model | Accuracy | F1 | Params | Time |
|-------|----------|-----|--------|------|
| **ResNet-18** | **100.0%** | 1.000 | 11M | 5 min |
| Baseline CNN | 98.86% | 0.989 | ~1M | 7 min |
| ViT | 98.86% | 0.989 | 86M | 15 min |

**–í—ã–≤–æ–¥:** ResNet-18 –æ–ø—Ç–∏–º–∞–ª–µ–Ω –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º

### 4.3 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

#### Primary Classifier
![Model Comparison](models/model_comparison.png)
- ResNet-18: Perfect classification
- –ë—ã—Å—Ç—Ä–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è
- –°—Ç–∞–±–∏–ª—å–Ω–∞—è validation

#### U-Net Segmentation
![Training History](models/unet_retina/training_history.png)
- Dice –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 0.51
- Convergence –ø–æ—Å–ª–µ 10 epochs
- Early stopping –Ω–∞ epoch 10

![Predictions](models/unet_retina/predictions.png)
- Overlay visualization
- –ö—Ä–∞—Å–Ω—ã–µ —Å–æ—Å—É–¥—ã –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏

#### YOLOv8 Detection
![Results](models/yolov8_bccd/results.png)
- mAP50: 0.935 (–æ—Ç–ª–∏—á–Ω–æ)
- Precision/Recall balance
- Fast convergence (12 epochs)

![Confusion Matrix](models/yolov8_bccd/confusion_matrix_normalized.png)
- WBC: 98.9% –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ confusion –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏

#### CIFAR-10 Classification
![Training History](models/resnet18_cifar10/training_history.png)
- Accuracy 82.87%
- Smooth learning curve
- LR reduction –Ω–∞ epochs 7, 10

![Confusion Matrix](models/resnet18_cifar10/confusion_matrix.png)
- Truck/Automobile confusion
- Cat/Dog confusion (–æ–∂–∏–¥–∞–µ–º–æ)

---

## 5. Telegram Bot

### 5.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**Framework:** aiogram 3.3.0 (async)

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
```python
bot/
‚îú‚îÄ‚îÄ main.py              # Entry point + bot initialization
‚îú‚îÄ‚îÄ config.py            # Configuration from .env
‚îú‚îÄ‚îÄ handlers.py          # Command & photo handlers
‚îú‚îÄ‚îÄ models_loader.py     # Singleton models manager
‚îî‚îÄ‚îÄ utils.py             # Helper functions
```

**Features:**
- ‚úÖ Async/await –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- ‚úÖ Singleton pattern –¥–ª—è –º–æ–¥–µ–ª–µ–π (load once)
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—É—Ç–∏–Ω–≥ –ø–æ —Ç–∏–ø—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- ‚úÖ Error handling + timeout
- ‚úÖ Logging (console + file)

### 5.2 Workflow

```python
@router.message(F.photo)
async def handle_photo(message: Message):
    # 1. Download photo
    image = await download_photo(bot, message)
    
    # 2. Primary classification
    image_type, confidence, _ = models.classify_image_type(image)
    
    # 3. Route to specialized model
    if image_type == 'retina':
        await process_retina(message, image)
    elif image_type == 'blood':
        await process_blood(message, image)
    elif image_type == 'scene':
        await process_scene(message, image)
```

### 5.3 Response Examples

#### Retina Segmentation
```
üî¨ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å–µ—Ç—á–∞—Ç–∫–∏

‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ!

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
‚Ä¢ –°–æ—Å—É–¥—ã –≤—ã–¥–µ–ª–µ–Ω—ã –∫—Ä–∞—Å–Ω—ã–º —Ü–≤–µ—Ç–æ–º
‚Ä¢ –ü–ª–æ—â–∞–¥—å —Å–æ—Å—É–¥–æ–≤: 15.3%

–ú–µ—Ç–æ–¥: U-Net (Dice: 0.51)
```
+ Overlay image

#### Blood Cell Detection
```
ü©∏ –î–µ—Ç–µ–∫—Ü–∏—è –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏

‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ: 52 –æ–±—ä–µ–∫—Ç–∞

üìä –ü–æ–¥—Å—á—ë—Ç –∫–ª–µ—Ç–æ–∫:
**–í—Å–µ–≥–æ –∫–ª–µ—Ç–æ–∫:** 52

‚Ä¢ **WBC:** 2 (3.8%)
‚Ä¢ **RBC:** 45 (86.5%)
‚Ä¢ **Platelets:** 5 (9.6%)

–ú–æ–¥–µ–ª—å: YOLOv8n (mAP50: 0.935)
```
+ Annotated image

#### Scene Classification
```
üåÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ü–µ–Ω—ã

‚úÖ **–†–µ–∑—É–ª—å—Ç–∞—Ç:** AIRPLANE
–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 87.5%

üìä –¢–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:
ü•á **airplane** - 87.5%
ü•à **ship** - 8.2%
ü•â **bird** - 2.1%

–ú–æ–¥–µ–ª—å: ResNet-18 (Accuracy: 85%+)
```

### 5.4 –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

| Operation | Time |
|-----------|------|
| Photo download | ~0.5s |
| Primary classification | ~0.1s |
| U-Net segmentation | ~1-2s |
| YOLO detection | ~0.5-1s |
| CIFAR-10 classification | ~0.1s |
| **Total** | **3-5s** |

### 5.5 Deployment

**–ó–∞–ø—É—Å–∫:**
```bash
# 1. Setup environment
conda activate ml-python312

# 2. Create .env
echo "TELEGRAM_BOT_TOKEN=your_token" > .env

# 3. Run bot
./run_bot.sh
```

**–°—Ç–∞—Ç—É—Å:** ‚úÖ Fully functional
- –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- Webhook conflict —Ä–µ—à—ë–Ω (auto-delete)
- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö

---

## 6. –í—ã–≤–æ–¥—ã

### 6.1 –î–æ—Å—Ç–∏–∂–µ–Ω–∏—è

‚úÖ **Primary Classification:**
- 3 –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –æ–±—É—á–µ–Ω—ã –∏ —Å—Ä–∞–≤–Ω–µ–Ω—ã
- ResNet-18: 100% accuracy
- Perfect routing –¥–ª—è production

‚úÖ **Medical Segmentation:**
- U-Net Dice 0.51 –Ω–∞ –º–∞–ª–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å overlay
- –ú–µ—Ç—Ä–∏–∫–∏ (Dice, IoU, precision, recall)

‚úÖ **Object Detection:**
- YOLOv8 mAP50 0.935 (–æ—Ç–ª–∏—á–Ω–æ)
- 3 –∫–ª–∞—Å—Å–∞ –∫–ª–µ—Ç–æ–∫
- –ë—ã—Å—Ç—Ä—ã–π inference (~1s)

‚úÖ **Scene Classification:**
- CIFAR-10: 82.87% accuracy
- –ë–ª–∏–∑–∫–æ –∫ —Ü–µ–ª–µ–≤–æ–π –º–µ—Ç—Ä–∏–∫–µ 85%
- Top-K predictions

‚úÖ **Telegram Bot:**
- –ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—É—Ç–∏–Ω–≥
- User-friendly –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- Production-ready

### 6.2 –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è

**Code Quality:**
- üìù ~4,800 —Å—Ç—Ä–æ–∫ —á–∏—Å—Ç–æ–≥–æ –∫–æ–¥–∞
- üèóÔ∏è –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
- üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- ‚úÖ Type hints + docstrings

**Performance:**
- ‚ö° –ë—ã—Å—Ç—Ä—ã–π inference (3-5s total)
- üîÑ Async processing
- üíæ Efficient memory usage
- üéØ Singleton pattern –¥–ª—è –º–æ–¥–µ–ª–µ–π

**Reproducibility:**
- üì¶ requirements.txt
- üêö Shell scripts –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
- üìñ –ü–æ–¥—Ä–æ–±–Ω—ã–µ README
- üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

### 6.3 –ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è

**–ü—Ä–æ–±–ª–µ–º–∞ 1:** –ú–∞–ª—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è U-Net (20 images)
- **–†–µ—à–µ–Ω–∏–µ:** Aggressive augmentation + pos_weight –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
- **–†–µ–∑—É–ª—å—Ç–∞—Ç:** Dice 0.51 (–ø—Ä–∏–µ–º–ª–µ–º–æ)

**–ü—Ä–æ–±–ª–µ–º–∞ 2:** PyTorch 2.6 weights_only=True
- **–†–µ—à–µ–Ω–∏–µ:** –î–æ–±–∞–≤–ª–µ–Ω weights_only=False –≤–æ –≤—Å–µ torch.load()
- **–†–µ–∑—É–ª—å—Ç–∞—Ç:** –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

**–ü—Ä–æ–±–ª–µ–º–∞ 3:** Webhook conflict –≤ Telegram
- **–†–µ—à–µ–Ω–∏–µ:** Auto delete webhook –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
- **–†–µ–∑—É–ª—å—Ç–∞—Ç:** Polling —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ

**–ü—Ä–æ–±–ª–µ–º–∞ 4:** CIFAR-10 accuracy 82.87% < 85% target
- **–ê–Ω–∞–ª–∏–∑:** Cat/Dog confusion, small image size
- **–†–µ—à–µ–Ω–∏–µ:** –ü—Ä–∏–µ–º–ª–µ–º–æ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –±–æ–ª—å—à–∏–º –æ–±—É—á–µ–Ω–∏–µ–º

### 6.4 –í–æ–∑–º–æ–∂–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

**Models:**
1. **U-Net:** –û–±—É—á–∏—Ç—å –Ω–∞ –±–æ–ª—å—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (STARE, CHASE-DB1)
2. **CIFAR-10:** –£–≤–µ–ª–∏—á–∏—Ç—å epochs –¥–æ 30-50, –¥–æ–±–∞–≤–∏—Ç—å augmentation
3. **Primary:** –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –∫–ª–∞—Å—Å–æ–≤ (X-ray, MRI, etc.)

**Bot:**
1. –î–æ–±–∞–≤–∏—Ç—å FSM –¥–ª—è multi-step dialogs
2. –ò—Å—Ç–æ—Ä–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
3. Batch processing –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–æ—Ç–æ
4. Webhook deployment –¥–ª—è production

**Infrastructure:**
1. Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
2. GPU support –¥–ª—è faster inference
3. Model quantization –¥–ª—è –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤
4. A/B testing –¥–ª—è model versions

### 6.5 –ò—Ç–æ–≥–∏

**–ü—Ä–æ–µ–∫—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –Ω–∞ 95%+:**
- ‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã (6/6)
- ‚úÖ –í—Å–µ inference –º–æ–¥—É–ª–∏ —Å–æ–∑–¥–∞–Ω—ã (4/4)
- ‚úÖ Telegram Bot –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–µ–Ω
- ‚úÖ –ö–æ–¥ –≤ GitHub
- ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞

**–ú–µ—Ç—Ä–∏–∫–∏:**
- Primary: **100%** ‚úì
- U-Net: **Dice 0.51** ‚úì
- YOLO: **mAP50 0.935** ‚úì
- CIFAR-10: **82.87%** ~ (target 85%)
- Bot: **Production-ready** ‚úì

**–í—Ä–µ–º—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏:** ~20 —á–∞—Å–æ–≤
**–°—Ç—Ä–æ–∫ –∫–æ–¥–∞:** ~4,800
**–ú–æ–¥–µ–ª–µ–π:** 6
**Commits:** 1 initial (82 files)

---

## 7. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è

### 7.1 –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

**Hardware:**
- CPU: 4+ cores (ARM/x86)
- RAM: 8GB+
- Storage: 10GB+ (–¥–ª—è datasets)

**Software:**
- Python 3.12
- Conda/Miniconda
- Git

### 7.2 Dependencies

–û—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–∏–∑ requirements.txt):
```
torch>=2.1.0
torchvision>=0.16.0
ultralytics>=8.0.0
aiogram>=3.3.0
opencv-python>=4.8.0
Pillow>=10.0.0
numpy>=1.24.0
matplotlib>=3.7.0
scikit-learn>=1.3.0
```

### 7.3 –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è

```bash
# 1. Clone repository
git clone https://github.com/kazdoraw/Classification-TG-bot.git
cd Classification-TG-bot

# 2. Setup environment
conda create -n ml-python312 python=3.12
conda activate ml-python312
pip install -r requirements.txt

# 3. Download datasets (—Å–º. DATASET_ANALYSIS.md)
python setup_datasets.py

# 4. Train models
./train_resnet_fast.sh          # Primary (5 min)
./train_unet_retina.sh          # U-Net (10 min)
./train_blood_detector.sh       # YOLO (10 min)
./train_cifar10_classifier.sh   # CIFAR-10 (90 min)

# 5. Test inference
./test_inference.sh

# 6. Run bot
echo "TELEGRAM_BOT_TOKEN=your_token" > .env
./run_bot.sh
```

### 7.4 Links

- **Repository:** https://github.com/kazdoraw/Classification-TG-bot
- **Telegram Bot:** @testgazragbot
- **DRIVE Dataset:** https://drive.grand-challenge.org/
- **BCCD Dataset:** https://public.roboflow.com/object-detection/bccd
- **CIFAR-10:** https://www.cs.toronto.edu/~kriz/cifar.html

---

## –ë–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–∏

- **PyTorch Team** –∑–∞ –æ—Ç–ª–∏—á–Ω—ã–π framework
- **Ultralytics** –∑–∞ YOLOv8
- **aiogram** –∑–∞ async Telegram bot library
- **Kaggle** –∑–∞ datasets –∏ compute resources

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2 –¥–µ–∫–∞–±—Ä—è 2024  
**–í–µ—Ä—Å–∏—è:** 1.0.0  
**–°—Ç–∞—Ç—É—Å:** ‚úÖ Production Ready
